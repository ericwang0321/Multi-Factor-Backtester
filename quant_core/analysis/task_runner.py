# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np
import os
from .preprocessor import FactorPreprocessor
from .research_engine import FactorResearchEngine
from ..factors.engine import FactorEngine 

class FactorTaskRunner:
    """
    Orchestrator for Factor EDA passing horizon parameters to the engine.
    Now fully adapted for Parquet DataQueryHelper.
    """
    
    def __init__(self, query_helper):
        """
        Args:
            query_helper: The Parquet-based data query helper
        """
        # åˆå§‹åŒ–å› å­å¼•æ“ (ä¼ å…¥ query_helper)
        self.factor_engine = FactorEngine(query_helper)
        self.preprocessor = FactorPreprocessor()

    def _get_cleaned_returns(self, horizon=1):
        """
        Prepare forward returns with cleaning and clipping using QueryHelper
        """
        # ä½¿ç”¨ QueryHelper è·å–å…¨é‡æ•°æ®
        df = self.factor_engine.query_helper.get_all_price_data()
        
        # ç¡®ä¿æ’åºæ­£ç¡®
        df = df.sort_values(['sec_code', 'datetime'])
        
        # è®¡ç®—é¢„æµ‹å‘¨æœŸçš„æ”¶ç›Šç‡ (Shift -N)
        df['ret_nd'] = df.groupby('sec_code')['close'].shift(-horizon) / df['close'] - 1
        
        # æå€¼è£å‰ªï¼Œé˜²æ­¢æç«¯åç‚¹ (ä¾‹å¦‚ Â±50%)
        df['ret_nd'] = df['ret_nd'].clip(-0.5, 0.5)
        
        return df[['datetime', 'sec_code', 'ret_nd']]

    def run_analysis_pipeline(self, factor_name, horizon=1, n_groups=5):
        print(f"ğŸš€ Running Factor EDA: {factor_name} (Horizon: {horizon}D)")

        # 1. è®¡ç®—å› å­ (FactorEngine ä¼šè‡ªåŠ¨ä» Parquet è¯»å–æ•°æ®)
        factor_df_wide = self.factor_engine._compute_and_cache_factor(factor_name)
        
        # å¦‚æœå› å­è®¡ç®—è¿”å›ç©º (æ¯”å¦‚è¢«ç¦ç”¨äº†)ï¼Œç›´æ¥è¿”å›ç©ºç»“æœé˜²æ­¢æŠ¥é”™
        if factor_df_wide.empty:
            print(f"âš ï¸ Factor {factor_name} returned empty data.")
            return {}, pd.DataFrame(), pd.DataFrame()

        factor_df = factor_df_wide.stack(future_stack=True).reset_index()
        factor_df.columns = ['datetime', 'sec_code', 'factor_value']

        # 2. è·å–æ”¶ç›Šç‡
        returns_df = self._get_cleaned_returns(horizon=horizon)

        # 3. å¯¹é½
        merged_df = pd.merge(factor_df, returns_df, on=['datetime', 'sec_code'], how='inner')
        merged_df = merged_df.dropna(subset=['factor_value', 'ret_nd'])

        # 4. é¢„å¤„ç† (å»æå€¼ã€æ ‡å‡†åŒ–)
        def clean_daily(group):
            group['factor_value'] = self.preprocessor.handle_outliers(group['factor_value'])
            group['factor_value'] = self.preprocessor.standardize(group['factor_value'])
            return group
        
        if merged_df.empty:
             print("âš ï¸ No valid data after merging factor and returns.")
             return {}, pd.DataFrame(), pd.DataFrame()

        cleaned_df = merged_df.groupby('datetime', group_keys=False).apply(clean_daily)

        # 5. æŒ‡æ ‡è®¡ç®—ï¼šä¼ å…¥ horizon ä»¥è°ƒæ•´å¤åˆ©é€»è¾‘
        res_engine = FactorResearchEngine(cleaned_df)
        ic_series = res_engine.calculate_ic(target_col='ret_nd', method='rank')
        stats = res_engine.calculate_stats(ic_series)
        
        # Quantile Analysis
        _, cum_group_ret, _ = res_engine.calculate_group_returns(target_col='ret_nd', n_groups=n_groups, horizon=horizon)

        return stats, ic_series, cum_group_ret