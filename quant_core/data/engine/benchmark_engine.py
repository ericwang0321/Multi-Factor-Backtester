# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np
from ib_insync import *
import duckdb
from datetime import datetime
import os
import traceback

# --- é…ç½® ---
IB_PORT = 7497  # æ¨¡æ‹Ÿç›˜ç«¯å£
CLIENT_ID = 99 
# è·¯å¾„ä¿®æ­£ï¼šç¡®ä¿æŒ‡å‘æ­£ç¡®çš„ Parquet æ–‡ä»¶
PARQUET_PATH = '../../../data/processed/all_price_data.parquet'

BENCHMARKS = {
    'SPY': 'SPY',   # S&P 500
    'ACWI': 'ACWI', # Global Equity
    'AGG': 'AGG',   # Global Bond
    'GSG': 'GSG'    # Commodity
}

def fetch_benchmark_data(ib: IB, symbol: str):
    """ä¸‹è½½å•ä¸ª ETF å…¨é‡æ•°æ®"""
    print(f"ğŸ“¥ Downloading {symbol} (Adjusted - ALL HISTORY)...")
    
    contract = Stock(symbol, 'SMART', 'USD')
    details = ib.reqContractDetails(contract)
    if not details:
        print(f"âš ï¸ Contract not found: {symbol}")
        return pd.DataFrame()
    contract = details[0].contract

    # ä¸‹è½½ 50 å¹´æ•°æ®
    bars = ib.reqHistoricalData(
        contract, endDateTime='', durationStr='50 Y', barSizeSetting='1 day',
        whatToShow='ADJUSTED_LAST', useRTH=True, formatDate=1
    )
    if not bars: return pd.DataFrame()

    df = util.df(bars)
    
    # --- æ•°æ®æ¸…æ´— ---
    df['datetime'] = pd.to_datetime(df['date'])
    df['sec_code'] = symbol
    df['category_id'] = 'benchmark'
    
    # [æ ¸å¿ƒä¿®å¤ 1] å¼ºåˆ¶æŠŠ create_time è½¬ä¸ºå­—ç¬¦ä¸²ï¼Œä¸æ—§æ•°æ®å…¼å®¹
    df['create_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    # å…³é”®å­—æ®µè¡¥å…¨
    if 'average' in df.columns:
        df = df.rename(columns={'average': 'avg_price'})
    else:
        df['avg_price'] = df['close']
    
    df['amount'] = df['volume'] * df['close']
    df['pre_close'] = df['close'].shift(1)
    df['simple_return'] = df['close'].pct_change()
    
    # å¡«å……ç¼ºå¤±åˆ—
    df['id'] = 0 
    df['barCount'] = df['barCount'] if 'barCount' in df.columns else 0
    df['shares_outstanding'] = 0.0
    df['turnover'] = 0.0
    df['market_cap'] = 0.0
    
    # è¡¥å…¨ 'id' åˆ°åˆ—è¡¨
    required_cols = [
        'id', 'datetime', 'sec_code', 'open', 'high', 'low', 'close', 
        'volume', 'amount', 'avg_price', 'category_id', 
        'pre_close', 'simple_return', 'shares_outstanding', 
        'turnover', 'market_cap', 'create_time', 'barCount'
    ]
    
    available_cols = [c for c in required_cols if c in df.columns]
    return df[available_cols].dropna(subset=['close'])

def update_parquet_storage(new_df):
    """åˆå¹¶æ•°æ®å¹¶è‡ªåŠ¨å¤„ç† ID"""
    if new_df.empty: return

    abs_parquet_path = os.path.abspath(os.path.join(os.path.dirname(__file__), PARQUET_PATH))
    print(f"ğŸ’¾ Updating Storage: {abs_parquet_path}")

    con = duckdb.connect()
    try:
        if os.path.exists(abs_parquet_path):
            # 1. è¯»å–æ—§æ•°æ®
            existing_df = con.execute(f"SELECT * FROM '{abs_parquet_path}'").df()
            
            # å‰”é™¤æ—§ Benchmark
            df_clean = existing_df[existing_df['category_id'] != 'benchmark'].copy()
            
            # [æ ¸å¿ƒä¿®å¤ 2] åŒé‡ä¿é™©ï¼šç¡®ä¿ä¸¤è¾¹éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹
            if 'create_time' in df_clean.columns:
                df_clean['create_time'] = df_clean['create_time'].astype(str)
            if 'create_time' in new_df.columns:
                new_df['create_time'] = new_df['create_time'].astype(str)

            # ID è‡ªå¢é€»è¾‘
            max_id = df_clean['id'].max() if not df_clean.empty else 0
            new_df['id'] = range(max_id + 1, max_id + 1 + len(new_df))
            
            # åˆå¹¶
            combined_df = pd.concat([df_clean, new_df], ignore_index=True)
        else:
            new_df['id'] = range(1, len(new_df) + 1)
            # ç¡®ä¿ç±»å‹æ˜¯å­—ç¬¦ä¸²
            new_df['create_time'] = new_df['create_time'].astype(str)
            combined_df = new_df

        # 2. å†™å…¥
        combined_df.sort_values(['sec_code', 'datetime'], inplace=True)
        combined_df.to_parquet(abs_parquet_path, index=False)
        print(f"âœ… Success! Database updated. Total rows: {len(combined_df)}")
        
    except Exception as e:
        print(f"âŒ Storage Error: {e}")
        traceback.print_exc()
    finally:
        con.close()

# ... (å‰é¢çš„ fetch_benchmark_data å’Œ update_parquet_storage å‡½æ•°ä¿æŒä¸å˜) ...

# [æ–°å¢/ä¿®æ”¹] å°è£…ä¸€ä¸ªä¾›å¤–éƒ¨è°ƒç”¨çš„å‡½æ•°
def sync_benchmarks(ib: IB):
    """
    ä¾› DataManager è°ƒç”¨çš„æ¥å£
    """
    print("\n--- Starting Benchmark Sync ---")
    all_data = []
    for name, symbol in BENCHMARKS.items():
        df = fetch_benchmark_data(ib, symbol)
        if not df.empty:
            print(f"   -> Got {len(df)} rows for {symbol}")
            all_data.append(df)
    
    if all_data:
        full_df = pd.concat(all_data)
        update_parquet_storage(full_df)
    else:
        print("âš ï¸ No benchmark data downloaded.")
    print("--- Benchmark Sync Finished ---\n")

# [ä¿®æ”¹] main å‡½æ•°ä»…ç”¨äºç‹¬ç«‹æµ‹è¯•
def main():
    ib = IB()
    try:
        print(f"Connecting to IBKR on port {IB_PORT}...")
        ib.connect('127.0.0.1', IB_PORT, clientId=CLIENT_ID)
        print("âœ… Connected.")
        
        # è°ƒç”¨ä¸Šé¢çš„å°è£…å‡½æ•°
        sync_benchmarks(ib)

    except Exception as e:
        print(f"âŒ Error: {e}")
    finally:
        ib.disconnect()

if __name__ == '__main__':
    main()